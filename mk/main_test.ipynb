{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15521,"status":"ok","timestamp":1688207066281,"user":{"displayName":"박민규","userId":"12628046480347201618"},"user_tz":-540},"id":"cr2Fkd-rjLuu","outputId":"f77f93b2-e71f-4c5a-e8b8-24c0de87f32d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"name":"stderr","output_type":"stream","text":["2023-07-01 10:24:20.030690: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-07-01 10:24:24.063382: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/usr/local/lib/python3.10/dist-packages/pandas_datareader/compat/__init__.py:11: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n","  PANDAS_VERSION = LooseVersion(pd.__version__)\n","/usr/local/lib/python3.10/dist-packages/pyfolio/pos.py:26: UserWarning: Module \"zipline.assets\" not found; mutltipliers will not be applied to position notionals.\n","  warnings.warn(\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import sys\n","sys.path.append(\"/content/drive/MyDrive/kubig_financial/finrl\")\n","\n","# ## install required packages\n","# !pip install gym\n","# !pip install stockstats\n","# !pip install gymnasium\n","# !pip install stable_baselines3\n","# !pip install alpaca_trade_api\n","# !pip install exchange_calendars\n","# !pip install pyfolio\n","# !pip install matplotlib\n","# !pip install swig\n","# !pip install wrds\n","# !pip install pyportfolioopt\n","# !pip install --upgrade ipykernel\n","# ## install finrl library\n","# !apt-get update -y -qq && apt-get install -y -qq cmake libopenmpi-dev python3-dev zlib1g-dev libgl1-mesa-glx swig\n","\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","# matplotlib.use('Agg')\n","import datetime\n","\n","%matplotlib inline\n","from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n","from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n","from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n","from finrl.agents.stablebaselines3.models import DRLAgent\n","from stable_baselines3.common.logger import configure\n","from finrl.meta.data_processor import DataProcessor\n","\n","from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n","from pprint import pprint\n","\n","import itertools\n","\n","from finrl import config\n","from finrl import config_tickers\n","import os\n","from finrl.main import check_and_make_directories\n","from finrl.config import (\n","    DATA_SAVE_DIR,\n","    TRAINED_MODEL_DIR,\n","    TENSORBOARD_LOG_DIR,\n","    RESULTS_DIR,\n","    INDICATORS,\n","    TRAIN_START_DATE,\n","    TRAIN_END_DATE,\n","    TEST_START_DATE,\n","    TEST_END_DATE,\n","    TRADE_START_DATE,\n","    TRADE_END_DATE,\n",")\n","check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4748,"status":"ok","timestamp":1688207079139,"user":{"displayName":"박민규","userId":"12628046480347201618"},"user_tz":-540},"id":"ezcDMqSzlT4n","outputId":"2239ae16-95f8-4ad2-d78a-1253a16c8f11"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/kubig_financial\n","dataset\t\t      finrl\t\t  prev\t       resultsa2c\n","datasets\t      finrl_module.ipynb  __pycache__  tensorboard_log\n","Dlinear_module.ipynb  finrl_module.py\t  result       trained_models\n","dlinear_module.py     main_test.ipynb\t  results      trials\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["%cd /content/drive/MyDrive/kubig_financial\n","!ls\n","import dlinear_module\n","import finrl_module"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":376604,"status":"ok","timestamp":1688207458503,"user":{"displayName":"박민규","userId":"12628046480347201618"},"user_tz":-540},"id":"v9Q9kzx9jd7B","outputId":"3db3fcf1-d4f3-47c7-ffc3-f6243c1a5005"},"outputs":[{"name":"stdout","output_type":"stream","text":["start_date :  2009-01-01 end_date :  2023-07-01 tickers :  ['XLB', 'XLE', 'XLF', 'XLI', 'XLK', 'XLP', 'XLU', 'XLV', 'XLY']\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","Shape of DataFrame:  (32832, 8)\n","prediction_start_index 252\n","test_start_index 3209\n","3209 691\n","2927 409 3366\n","test_loader 13\n","torch.Size([32, 252, 9])\n","252\n","30\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 13/13 [00:00<00:00, 58.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Test Loss: 707.463135\n","torch.Size([409, 30, 9])\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 106/106 [00:01<00:00, 72.23it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Test Loss: 415.157074\n","torch.Size([3366, 30, 9])\n","end\n","['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma']\n","Successfully added technical indicators\n","[*********************100%***********************]  1 of 1 completed\n","Shape of DataFrame:  (3647, 8)\n","Successfully added vix\n","Successfully added turbulence index\n","Stock Dimension: 9, State Space: 118\n","{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n","Using cpu device\n","Logging to resultsa2c\n","----------------------------------------\n","| time/                 |              |\n","|    fps                | 163          |\n","|    iterations         | 100          |\n","|    time_elapsed       | 3            |\n","|    total_timesteps    | 500          |\n","| train/                |              |\n","|    entropy_loss       | -12.8        |\n","|    explained_variance | -10.9        |\n","|    learning_rate      | 0.0007       |\n","|    n_updates          | 99           |\n","|    policy_loss        | -0.164       |\n","|    reward             | -0.025671642 |\n","|    std                | 1.01         |\n","|    value_loss         | 0.423        |\n","----------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 137       |\n","|    iterations         | 200       |\n","|    time_elapsed       | 7         |\n","|    total_timesteps    | 1000      |\n","| train/                |           |\n","|    entropy_loss       | -12.8     |\n","|    explained_variance | -0.859    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 199       |\n","|    policy_loss        | -10.8     |\n","|    reward             | -1.042364 |\n","|    std                | 1.01      |\n","|    value_loss         | 0.995     |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 135       |\n","|    iterations         | 300       |\n","|    time_elapsed       | 11        |\n","|    total_timesteps    | 1500      |\n","| train/                |           |\n","|    entropy_loss       | -12.8     |\n","|    explained_variance | -1.92     |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 299       |\n","|    policy_loss        | -41.2     |\n","|    reward             | 2.5507646 |\n","|    std                | 1.01      |\n","|    value_loss         | 12.1      |\n","-------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 143         |\n","|    iterations         | 400         |\n","|    time_elapsed       | 13          |\n","|    total_timesteps    | 2000        |\n","| train/                |             |\n","|    entropy_loss       | -12.8       |\n","|    explained_variance | 0           |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 399         |\n","|    policy_loss        | -8.99       |\n","|    reward             | -0.53239125 |\n","|    std                | 1           |\n","|    value_loss         | 6.29        |\n","---------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 147       |\n","|    iterations         | 500       |\n","|    time_elapsed       | 16        |\n","|    total_timesteps    | 2500      |\n","| train/                |           |\n","|    entropy_loss       | -12.8     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 499       |\n","|    policy_loss        | 72.7      |\n","|    reward             | -7.468741 |\n","|    std                | 1         |\n","|    value_loss         | 47.7      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 147        |\n","|    iterations         | 600        |\n","|    time_elapsed       | 20         |\n","|    total_timesteps    | 3000       |\n","| train/                |            |\n","|    entropy_loss       | -12.8      |\n","|    explained_variance | -1.19e-07  |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 599        |\n","|    policy_loss        | 30.9       |\n","|    reward             | -0.9050221 |\n","|    std                | 1.01       |\n","|    value_loss         | 11.8       |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 140         |\n","|    iterations         | 700         |\n","|    time_elapsed       | 24          |\n","|    total_timesteps    | 3500        |\n","| train/                |             |\n","|    entropy_loss       | -12.8       |\n","|    explained_variance | -3.11       |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 699         |\n","|    policy_loss        | -17.2       |\n","|    reward             | -0.13172172 |\n","|    std                | 1.01        |\n","|    value_loss         | 2.51        |\n","---------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 144        |\n","|    iterations         | 800        |\n","|    time_elapsed       | 27         |\n","|    total_timesteps    | 4000       |\n","| train/                |            |\n","|    entropy_loss       | -12.8      |\n","|    explained_variance | 0.00252    |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 799        |\n","|    policy_loss        | -5.33      |\n","|    reward             | 0.66491264 |\n","|    std                | 1.01       |\n","|    value_loss         | 0.579      |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 146        |\n","|    iterations         | 900        |\n","|    time_elapsed       | 30         |\n","|    total_timesteps    | 4500       |\n","| train/                |            |\n","|    entropy_loss       | -12.8      |\n","|    explained_variance | -0.231     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 899        |\n","|    policy_loss        | 50.9       |\n","|    reward             | 0.79626244 |\n","|    std                | 1.01       |\n","|    value_loss         | 29         |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 148       |\n","|    iterations         | 1000      |\n","|    time_elapsed       | 33        |\n","|    total_timesteps    | 5000      |\n","| train/                |           |\n","|    entropy_loss       | -12.8     |\n","|    explained_variance | -0.0196   |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 999       |\n","|    policy_loss        | -91       |\n","|    reward             | 3.9653506 |\n","|    std                | 1.01      |\n","|    value_loss         | 71.1      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 144        |\n","|    iterations         | 1100       |\n","|    time_elapsed       | 38         |\n","|    total_timesteps    | 5500       |\n","| train/                |            |\n","|    entropy_loss       | -12.9      |\n","|    explained_variance | -0.0146    |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1099       |\n","|    policy_loss        | -46.5      |\n","|    reward             | -13.649447 |\n","|    std                | 1.01       |\n","|    value_loss         | 21.9       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 144       |\n","|    iterations         | 1200      |\n","|    time_elapsed       | 41        |\n","|    total_timesteps    | 6000      |\n","| train/                |           |\n","|    entropy_loss       | -12.8     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1199      |\n","|    policy_loss        | 3.8       |\n","|    reward             | 3.9809248 |\n","|    std                | 1.01      |\n","|    value_loss         | 28.4      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 145        |\n","|    iterations         | 1300       |\n","|    time_elapsed       | 44         |\n","|    total_timesteps    | 6500       |\n","| train/                |            |\n","|    entropy_loss       | -12.8      |\n","|    explained_variance | -1.19e-07  |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1299       |\n","|    policy_loss        | 6.64       |\n","|    reward             | 0.81629604 |\n","|    std                | 1.01       |\n","|    value_loss         | 1.26       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 146       |\n","|    iterations         | 1400      |\n","|    time_elapsed       | 47        |\n","|    total_timesteps    | 7000      |\n","| train/                |           |\n","|    entropy_loss       | -12.9     |\n","|    explained_variance | 0.0207    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1399      |\n","|    policy_loss        | -27       |\n","|    reward             | 1.2357343 |\n","|    std                | 1.01      |\n","|    value_loss         | 3.8       |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 146       |\n","|    iterations         | 1500      |\n","|    time_elapsed       | 51        |\n","|    total_timesteps    | 7500      |\n","| train/                |           |\n","|    entropy_loss       | -12.9     |\n","|    explained_variance | -0.00276  |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1499      |\n","|    policy_loss        | -0.796    |\n","|    reward             | 1.5866637 |\n","|    std                | 1.01      |\n","|    value_loss         | 2.65      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 144        |\n","|    iterations         | 1600       |\n","|    time_elapsed       | 55         |\n","|    total_timesteps    | 8000       |\n","| train/                |            |\n","|    entropy_loss       | -12.9      |\n","|    explained_variance | 5.96e-08   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1599       |\n","|    policy_loss        | 21.3       |\n","|    reward             | -3.6036005 |\n","|    std                | 1.02       |\n","|    value_loss         | 4.24       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 145        |\n","|    iterations         | 1700       |\n","|    time_elapsed       | 58         |\n","|    total_timesteps    | 8500       |\n","| train/                |            |\n","|    entropy_loss       | -12.9      |\n","|    explained_variance | -1.19e-07  |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1699       |\n","|    policy_loss        | -6.42      |\n","|    reward             | -1.1763148 |\n","|    std                | 1.02       |\n","|    value_loss         | 0.368      |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 146       |\n","|    iterations         | 1800      |\n","|    time_elapsed       | 61        |\n","|    total_timesteps    | 9000      |\n","| train/                |           |\n","|    entropy_loss       | -13       |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1799      |\n","|    policy_loss        | 98.9      |\n","|    reward             | 1.3687749 |\n","|    std                | 1.02      |\n","|    value_loss         | 68.1      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 147       |\n","|    iterations         | 1900      |\n","|    time_elapsed       | 64        |\n","|    total_timesteps    | 9500      |\n","| train/                |           |\n","|    entropy_loss       | -13       |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1899      |\n","|    policy_loss        | -75.4     |\n","|    reward             | 15.783371 |\n","|    std                | 1.02      |\n","|    value_loss         | 68.2      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 145        |\n","|    iterations         | 2000       |\n","|    time_elapsed       | 68         |\n","|    total_timesteps    | 10000      |\n","| train/                |            |\n","|    entropy_loss       | -13        |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1999       |\n","|    policy_loss        | -1.69      |\n","|    reward             | 0.23705664 |\n","|    std                | 1.03       |\n","|    value_loss         | 2.06       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 145        |\n","|    iterations         | 2100       |\n","|    time_elapsed       | 72         |\n","|    total_timesteps    | 10500      |\n","| train/                |            |\n","|    entropy_loss       | -13        |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 2099       |\n","|    policy_loss        | -13.4      |\n","|    reward             | 0.30680364 |\n","|    std                | 1.03       |\n","|    value_loss         | 1.96       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 146       |\n","|    iterations         | 2200      |\n","|    time_elapsed       | 75        |\n","|    total_timesteps    | 11000     |\n","| train/                |           |\n","|    entropy_loss       | -13       |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2199      |\n","|    policy_loss        | 3.84      |\n","|    reward             | 1.2684029 |\n","|    std                | 1.03      |\n","|    value_loss         | 1.22      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 147       |\n","|    iterations         | 2300      |\n","|    time_elapsed       | 78        |\n","|    total_timesteps    | 11500     |\n","| train/                |           |\n","|    entropy_loss       | -13       |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2299      |\n","|    policy_loss        | -11.8     |\n","|    reward             | -3.226354 |\n","|    std                | 1.03      |\n","|    value_loss         | 1.29      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 146        |\n","|    iterations         | 2400       |\n","|    time_elapsed       | 81         |\n","|    total_timesteps    | 12000      |\n","| train/                |            |\n","|    entropy_loss       | -13        |\n","|    explained_variance | 1.19e-07   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 2399       |\n","|    policy_loss        | 6.4        |\n","|    reward             | -3.9417658 |\n","|    std                | 1.03       |\n","|    value_loss         | 2.26       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 145       |\n","|    iterations         | 2500      |\n","|    time_elapsed       | 86        |\n","|    total_timesteps    | 12500     |\n","| train/                |           |\n","|    entropy_loss       | -13       |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2499      |\n","|    policy_loss        | 49.5      |\n","|    reward             | 5.3900013 |\n","|    std                | 1.03      |\n","|    value_loss         | 32.3      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 146        |\n","|    iterations         | 2600       |\n","|    time_elapsed       | 89         |\n","|    total_timesteps    | 13000      |\n","| train/                |            |\n","|    entropy_loss       | -13        |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 2599       |\n","|    policy_loss        | 12.8       |\n","|    reward             | 0.09444695 |\n","|    std                | 1.03       |\n","|    value_loss         | 1.63       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 146        |\n","|    iterations         | 2700       |\n","|    time_elapsed       | 91         |\n","|    total_timesteps    | 13500      |\n","| train/                |            |\n","|    entropy_loss       | -13        |\n","|    explained_variance | 5.96e-08   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 2699       |\n","|    policy_loss        | 64.8       |\n","|    reward             | 0.51467603 |\n","|    std                | 1.03       |\n","|    value_loss         | 29.9       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 147        |\n","|    iterations         | 2800       |\n","|    time_elapsed       | 94         |\n","|    total_timesteps    | 14000      |\n","| train/                |            |\n","|    entropy_loss       | -13        |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 2799       |\n","|    policy_loss        | -2.21      |\n","|    reward             | -0.5987415 |\n","|    std                | 1.03       |\n","|    value_loss         | 0.78       |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 145         |\n","|    iterations         | 2900        |\n","|    time_elapsed       | 99          |\n","|    total_timesteps    | 14500       |\n","| train/                |             |\n","|    entropy_loss       | -13         |\n","|    explained_variance | 0           |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 2899        |\n","|    policy_loss        | -40.2       |\n","|    reward             | -0.74999756 |\n","|    std                | 1.03        |\n","|    value_loss         | 10.2        |\n","---------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 145        |\n","|    iterations         | 3000       |\n","|    time_elapsed       | 102        |\n","|    total_timesteps    | 15000      |\n","| train/                |            |\n","|    entropy_loss       | -13        |\n","|    explained_variance | 1.19e-07   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 2999       |\n","|    policy_loss        | -9.46      |\n","|    reward             | -0.5172859 |\n","|    std                | 1.03       |\n","|    value_loss         | 2.42       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 146        |\n","|    iterations         | 3100       |\n","|    time_elapsed       | 105        |\n","|    total_timesteps    | 15500      |\n","| train/                |            |\n","|    entropy_loss       | -13.1      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 3099       |\n","|    policy_loss        | 13.8       |\n","|    reward             | -21.959259 |\n","|    std                | 1.03       |\n","|    value_loss         | 7.14       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 146       |\n","|    iterations         | 3200      |\n","|    time_elapsed       | 108       |\n","|    total_timesteps    | 16000     |\n","| train/                |           |\n","|    entropy_loss       | -13       |\n","|    explained_variance | 1.19e-07  |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3199      |\n","|    policy_loss        | 192       |\n","|    reward             | 4.8343387 |\n","|    std                | 1.03      |\n","|    value_loss         | 333       |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 146        |\n","|    iterations         | 3300       |\n","|    time_elapsed       | 112        |\n","|    total_timesteps    | 16500      |\n","| train/                |            |\n","|    entropy_loss       | -13        |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 3299       |\n","|    policy_loss        | 22         |\n","|    reward             | 0.42913467 |\n","|    std                | 1.03       |\n","|    value_loss         | 3.34       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 145       |\n","|    iterations         | 3400      |\n","|    time_elapsed       | 116       |\n","|    total_timesteps    | 17000     |\n","| train/                |           |\n","|    entropy_loss       | -13       |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3399      |\n","|    policy_loss        | -54       |\n","|    reward             | 2.0499585 |\n","|    std                | 1.03      |\n","|    value_loss         | 16.8      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 146        |\n","|    iterations         | 3500       |\n","|    time_elapsed       | 119        |\n","|    total_timesteps    | 17500      |\n","| train/                |            |\n","|    entropy_loss       | -13.1      |\n","|    explained_variance | -1.19e-07  |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 3499       |\n","|    policy_loss        | -48.8      |\n","|    reward             | 0.32067284 |\n","|    std                | 1.03       |\n","|    value_loss         | 14.8       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 146        |\n","|    iterations         | 3600       |\n","|    time_elapsed       | 122        |\n","|    total_timesteps    | 18000      |\n","| train/                |            |\n","|    entropy_loss       | -13        |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 3599       |\n","|    policy_loss        | 8.14       |\n","|    reward             | -0.8036165 |\n","|    std                | 1.03       |\n","|    value_loss         | 1.87       |\n","--------------------------------------\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 146      |\n","|    iterations         | 3700     |\n","|    time_elapsed       | 125      |\n","|    total_timesteps    | 18500    |\n","| train/                |          |\n","|    entropy_loss       | -13.1    |\n","|    explained_variance | 0        |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 3699     |\n","|    policy_loss        | -14.6    |\n","|    reward             | 1.196326 |\n","|    std                | 1.03     |\n","|    value_loss         | 5.21     |\n","------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 145        |\n","|    iterations         | 3800       |\n","|    time_elapsed       | 130        |\n","|    total_timesteps    | 19000      |\n","| train/                |            |\n","|    entropy_loss       | -13.1      |\n","|    explained_variance | 5.96e-08   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 3799       |\n","|    policy_loss        | 36.2       |\n","|    reward             | -2.5061052 |\n","|    std                | 1.04       |\n","|    value_loss         | 123        |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 145       |\n","|    iterations         | 3900      |\n","|    time_elapsed       | 133       |\n","|    total_timesteps    | 19500     |\n","| train/                |           |\n","|    entropy_loss       | -13.1     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3899      |\n","|    policy_loss        | -4.17     |\n","|    reward             | 0.5186347 |\n","|    std                | 1.04      |\n","|    value_loss         | 0.237     |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 146        |\n","|    iterations         | 4000       |\n","|    time_elapsed       | 136        |\n","|    total_timesteps    | 20000      |\n","| train/                |            |\n","|    entropy_loss       | -13.1      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 3999       |\n","|    policy_loss        | 0.567      |\n","|    reward             | 0.42923504 |\n","|    std                | 1.04       |\n","|    value_loss         | 1.38       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 146        |\n","|    iterations         | 4100       |\n","|    time_elapsed       | 139        |\n","|    total_timesteps    | 20500      |\n","| train/                |            |\n","|    entropy_loss       | -13.2      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 4099       |\n","|    policy_loss        | 5.9        |\n","|    reward             | -0.6301818 |\n","|    std                | 1.04       |\n","|    value_loss         | 0.536      |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 145        |\n","|    iterations         | 4200       |\n","|    time_elapsed       | 144        |\n","|    total_timesteps    | 21000      |\n","| train/                |            |\n","|    entropy_loss       | -13.1      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 4199       |\n","|    policy_loss        | -5         |\n","|    reward             | -4.0844646 |\n","|    std                | 1.04       |\n","|    value_loss         | 1.01       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 145       |\n","|    iterations         | 4300      |\n","|    time_elapsed       | 147       |\n","|    total_timesteps    | 21500     |\n","| train/                |           |\n","|    entropy_loss       | -13.2     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 4299      |\n","|    policy_loss        | 38.1      |\n","|    reward             | -6.443632 |\n","|    std                | 1.05      |\n","|    value_loss         | 14.1      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 145        |\n","|    iterations         | 4400       |\n","|    time_elapsed       | 150        |\n","|    total_timesteps    | 22000      |\n","| train/                |            |\n","|    entropy_loss       | -13.2      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 4399       |\n","|    policy_loss        | -57        |\n","|    reward             | -1.7692196 |\n","|    std                | 1.04       |\n","|    value_loss         | 23         |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 146        |\n","|    iterations         | 4500       |\n","|    time_elapsed       | 153        |\n","|    total_timesteps    | 22500      |\n","| train/                |            |\n","|    entropy_loss       | -13.2      |\n","|    explained_variance | -0.147     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 4499       |\n","|    policy_loss        | -28.4      |\n","|    reward             | -1.4743501 |\n","|    std                | 1.04       |\n","|    value_loss         | 9.83       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 145        |\n","|    iterations         | 4600       |\n","|    time_elapsed       | 157        |\n","|    total_timesteps    | 23000      |\n","| train/                |            |\n","|    entropy_loss       | -13.2      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 4599       |\n","|    policy_loss        | 7.62       |\n","|    reward             | 0.15285216 |\n","|    std                | 1.04       |\n","|    value_loss         | 0.551      |\n","--------------------------------------\n","----------------------------------------\n","| time/                 |              |\n","|    fps                | 145          |\n","|    iterations         | 4700         |\n","|    time_elapsed       | 161          |\n","|    total_timesteps    | 23500        |\n","| train/                |              |\n","|    entropy_loss       | -13.1        |\n","|    explained_variance | 0            |\n","|    learning_rate      | 0.0007       |\n","|    n_updates          | 4699         |\n","|    policy_loss        | 7            |\n","|    reward             | -0.026456568 |\n","|    std                | 1.04         |\n","|    value_loss         | 0.947        |\n","----------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 145        |\n","|    iterations         | 4800       |\n","|    time_elapsed       | 164        |\n","|    total_timesteps    | 24000      |\n","| train/                |            |\n","|    entropy_loss       | -13.1      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 4799       |\n","|    policy_loss        | 30.4       |\n","|    reward             | 0.59487236 |\n","|    std                | 1.04       |\n","|    value_loss         | 8.87       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 145        |\n","|    iterations         | 4900       |\n","|    time_elapsed       | 168        |\n","|    total_timesteps    | 24500      |\n","| train/                |            |\n","|    entropy_loss       | -13.1      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 4899       |\n","|    policy_loss        | -18.7      |\n","|    reward             | 0.21791318 |\n","|    std                | 1.04       |\n","|    value_loss         | 5.05       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 146       |\n","|    iterations         | 5000      |\n","|    time_elapsed       | 171       |\n","|    total_timesteps    | 25000     |\n","| train/                |           |\n","|    entropy_loss       | -13.1     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 4999      |\n","|    policy_loss        | 64.7      |\n","|    reward             | 1.7132146 |\n","|    std                | 1.04      |\n","|    value_loss         | 38.4      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 144       |\n","|    iterations         | 5100      |\n","|    time_elapsed       | 175       |\n","|    total_timesteps    | 25500     |\n","| train/                |           |\n","|    entropy_loss       | -13.1     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 5099      |\n","|    policy_loss        | 135       |\n","|    reward             | -13.18307 |\n","|    std                | 1.03      |\n","|    value_loss         | 118       |\n","-------------------------------------\n","-----------------------------------------\n","| time/                 |               |\n","|    fps                | 145           |\n","|    iterations         | 5200          |\n","|    time_elapsed       | 178           |\n","|    total_timesteps    | 26000         |\n","| train/                |               |\n","|    entropy_loss       | -13.1         |\n","|    explained_variance | -64.2         |\n","|    learning_rate      | 0.0007        |\n","|    n_updates          | 5199          |\n","|    policy_loss        | -33.7         |\n","|    reward             | -0.0128075285 |\n","|    std                | 1.03          |\n","|    value_loss         | 9.49          |\n","-----------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 145       |\n","|    iterations         | 5300      |\n","|    time_elapsed       | 181       |\n","|    total_timesteps    | 26500     |\n","| train/                |           |\n","|    entropy_loss       | -13.1     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 5299      |\n","|    policy_loss        | -55       |\n","|    reward             | 2.9725664 |\n","|    std                | 1.04      |\n","|    value_loss         | 20.6      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 146       |\n","|    iterations         | 5400      |\n","|    time_elapsed       | 184       |\n","|    total_timesteps    | 27000     |\n","| train/                |           |\n","|    entropy_loss       | -13.1     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 5399      |\n","|    policy_loss        | -54.6     |\n","|    reward             | 1.9618146 |\n","|    std                | 1.04      |\n","|    value_loss         | 18.5      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 145       |\n","|    iterations         | 5500      |\n","|    time_elapsed       | 188       |\n","|    total_timesteps    | 27500     |\n","| train/                |           |\n","|    entropy_loss       | -13.2     |\n","|    explained_variance | 0.0593    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 5499      |\n","|    policy_loss        | 41.3      |\n","|    reward             | 0.2747017 |\n","|    std                | 1.05      |\n","|    value_loss         | 12.6      |\n","-------------------------------------\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 145      |\n","|    iterations         | 5600     |\n","|    time_elapsed       | 192      |\n","|    total_timesteps    | 28000    |\n","| train/                |          |\n","|    entropy_loss       | -13.2    |\n","|    explained_variance | 0        |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 5599     |\n","|    policy_loss        | -137     |\n","|    reward             | 5.51174  |\n","|    std                | 1.05     |\n","|    value_loss         | 184      |\n","------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 145       |\n","|    iterations         | 5700      |\n","|    time_elapsed       | 195       |\n","|    total_timesteps    | 28500     |\n","| train/                |           |\n","|    entropy_loss       | -13.2     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 5699      |\n","|    policy_loss        | -349      |\n","|    reward             | 19.965054 |\n","|    std                | 1.05      |\n","|    value_loss         | 788       |\n","-------------------------------------\n","day: 3208, episode: 10\n","begin_total_asset: 1000000.00\n","end_total_asset: 8829493.97\n","total_reward: 7829493.97\n","total_cost: 13428.92\n","total_trades: 18937\n","Sharpe: 1.023\n","=================================\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 145        |\n","|    iterations         | 5800       |\n","|    time_elapsed       | 198        |\n","|    total_timesteps    | 29000      |\n","| train/                |            |\n","|    entropy_loss       | -13.2      |\n","|    explained_variance | 0.378      |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 5799       |\n","|    policy_loss        | -9.33      |\n","|    reward             | 0.29449716 |\n","|    std                | 1.05       |\n","|    value_loss         | 1.41       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 146       |\n","|    iterations         | 5900      |\n","|    time_elapsed       | 202       |\n","|    total_timesteps    | 29500     |\n","| train/                |           |\n","|    entropy_loss       | -13.2     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 5899      |\n","|    policy_loss        | -31.1     |\n","|    reward             | 0.5435307 |\n","|    std                | 1.05      |\n","|    value_loss         | 5.6       |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 145        |\n","|    iterations         | 6000       |\n","|    time_elapsed       | 206        |\n","|    total_timesteps    | 30000      |\n","| train/                |            |\n","|    entropy_loss       | -13.2      |\n","|    explained_variance | 1.19e-07   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 5999       |\n","|    policy_loss        | 12.1       |\n","|    reward             | -0.8244312 |\n","|    std                | 1.05       |\n","|    value_loss         | 2.56       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 145       |\n","|    iterations         | 6100      |\n","|    time_elapsed       | 209       |\n","|    total_timesteps    | 30500     |\n","| train/                |           |\n","|    entropy_loss       | -13.2     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 6099      |\n","|    policy_loss        | -13.7     |\n","|    reward             | 2.7804663 |\n","|    std                | 1.05      |\n","|    value_loss         | 2.9       |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 145        |\n","|    iterations         | 6200       |\n","|    time_elapsed       | 212        |\n","|    total_timesteps    | 31000      |\n","| train/                |            |\n","|    entropy_loss       | -13.2      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 6199       |\n","|    policy_loss        | 42.4       |\n","|    reward             | 0.13206248 |\n","|    std                | 1.05       |\n","|    value_loss         | 11.4       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 146       |\n","|    iterations         | 6300      |\n","|    time_elapsed       | 215       |\n","|    total_timesteps    | 31500     |\n","| train/                |           |\n","|    entropy_loss       | -13.2     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 6299      |\n","|    policy_loss        | -64.9     |\n","|    reward             | -5.291503 |\n","|    std                | 1.05      |\n","|    value_loss         | 31.3      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 145        |\n","|    iterations         | 6400       |\n","|    time_elapsed       | 220        |\n","|    total_timesteps    | 32000      |\n","| train/                |            |\n","|    entropy_loss       | -13.2      |\n","|    explained_variance | 1.19e-07   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 6399       |\n","|    policy_loss        | -20.5      |\n","|    reward             | 0.31338495 |\n","|    std                | 1.05       |\n","|    value_loss         | 37.1       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 145       |\n","|    iterations         | 6500      |\n","|    time_elapsed       | 223       |\n","|    total_timesteps    | 32500     |\n","| train/                |           |\n","|    entropy_loss       | -13.1     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 6499      |\n","|    policy_loss        | -63.8     |\n","|    reward             | -2.061896 |\n","|    std                | 1.04      |\n","|    value_loss         | 29.3      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 145        |\n","|    iterations         | 6600       |\n","|    time_elapsed       | 226        |\n","|    total_timesteps    | 33000      |\n","| train/                |            |\n","|    entropy_loss       | -13.1      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 6599       |\n","|    policy_loss        | 30.1       |\n","|    reward             | 0.32940674 |\n","|    std                | 1.04       |\n","|    value_loss         | 7.49       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 145       |\n","|    iterations         | 6700      |\n","|    time_elapsed       | 229       |\n","|    total_timesteps    | 33500     |\n","| train/                |           |\n","|    entropy_loss       | -13.2     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 6699      |\n","|    policy_loss        | -34       |\n","|    reward             | 1.2861681 |\n","|    std                | 1.05      |\n","|    value_loss         | 14.3      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 145        |\n","|    iterations         | 6800       |\n","|    time_elapsed       | 233        |\n","|    total_timesteps    | 34000      |\n","| train/                |            |\n","|    entropy_loss       | -13.2      |\n","|    explained_variance | 1.79e-07   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 6799       |\n","|    policy_loss        | 5.7        |\n","|    reward             | 0.82496554 |\n","|    std                | 1.04       |\n","|    value_loss         | 0.436      |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 145       |\n","|    iterations         | 6900      |\n","|    time_elapsed       | 237       |\n","|    total_timesteps    | 34500     |\n","| train/                |           |\n","|    entropy_loss       | -13.2     |\n","|    explained_variance | 1.19e-07  |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 6899      |\n","|    policy_loss        | -8.28     |\n","|    reward             | 1.8488666 |\n","|    std                | 1.05      |\n","|    value_loss         | 2.67      |\n","-------------------------------------\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 145      |\n","|    iterations         | 7000     |\n","|    time_elapsed       | 240      |\n","|    total_timesteps    | 35000    |\n","| train/                |          |\n","|    entropy_loss       | -13.2    |\n","|    explained_variance | 1.19e-07 |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 6999     |\n","|    policy_loss        | 184      |\n","|    reward             | 8.002725 |\n","|    std                | 1.04     |\n","|    value_loss         | 238      |\n","------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 145         |\n","|    iterations         | 7100        |\n","|    time_elapsed       | 243         |\n","|    total_timesteps    | 35500       |\n","| train/                |             |\n","|    entropy_loss       | -13.1       |\n","|    explained_variance | 5.96e-08    |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 7099        |\n","|    policy_loss        | 5.37        |\n","|    reward             | -0.94600636 |\n","|    std                | 1.04        |\n","|    value_loss         | 0.56        |\n","---------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 145        |\n","|    iterations         | 7200       |\n","|    time_elapsed       | 246        |\n","|    total_timesteps    | 36000      |\n","| train/                |            |\n","|    entropy_loss       | -13.1      |\n","|    explained_variance | -1.19e-07  |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 7199       |\n","|    policy_loss        | 60         |\n","|    reward             | 0.21420604 |\n","|    std                | 1.04       |\n","|    value_loss         | 27.5       |\n","--------------------------------------\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 145      |\n","|    iterations         | 7300     |\n","|    time_elapsed       | 251      |\n","|    total_timesteps    | 36500    |\n","| train/                |          |\n","|    entropy_loss       | -13.1    |\n","|    explained_variance | 0        |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 7299     |\n","|    policy_loss        | -35.5    |\n","|    reward             | 5.480161 |\n","|    std                | 1.04     |\n","|    value_loss         | 8.78     |\n","------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 145        |\n","|    iterations         | 7400       |\n","|    time_elapsed       | 254        |\n","|    total_timesteps    | 37000      |\n","| train/                |            |\n","|    entropy_loss       | -13.1      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 7399       |\n","|    policy_loss        | -122       |\n","|    reward             | -1.5803518 |\n","|    std                | 1.04       |\n","|    value_loss         | 91.8       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 145       |\n","|    iterations         | 7500      |\n","|    time_elapsed       | 257       |\n","|    total_timesteps    | 37500     |\n","| train/                |           |\n","|    entropy_loss       | -13.1     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 7499      |\n","|    policy_loss        | -7.74     |\n","|    reward             | 1.9564614 |\n","|    std                | 1.04      |\n","|    value_loss         | 0.586     |\n","-------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 145         |\n","|    iterations         | 7600        |\n","|    time_elapsed       | 260         |\n","|    total_timesteps    | 38000       |\n","| train/                |             |\n","|    entropy_loss       | -13.1       |\n","|    explained_variance | 1.19e-07    |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 7599        |\n","|    policy_loss        | -30.7       |\n","|    reward             | -0.61329424 |\n","|    std                | 1.04        |\n","|    value_loss         | 12.2        |\n","---------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 145       |\n","|    iterations         | 7700      |\n","|    time_elapsed       | 264       |\n","|    total_timesteps    | 38500     |\n","| train/                |           |\n","|    entropy_loss       | -13       |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 7699      |\n","|    policy_loss        | -102      |\n","|    reward             | 0.3422231 |\n","|    std                | 1.03      |\n","|    value_loss         | 81.4      |\n","-------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 145         |\n","|    iterations         | 7800        |\n","|    time_elapsed       | 268         |\n","|    total_timesteps    | 39000       |\n","| train/                |             |\n","|    entropy_loss       | -13         |\n","|    explained_variance | -1.19e-07   |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 7799        |\n","|    policy_loss        | -2.9        |\n","|    reward             | -0.56218994 |\n","|    std                | 1.03        |\n","|    value_loss         | 0.421       |\n","---------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 145       |\n","|    iterations         | 7900      |\n","|    time_elapsed       | 271       |\n","|    total_timesteps    | 39500     |\n","| train/                |           |\n","|    entropy_loss       | -13.1     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 7899      |\n","|    policy_loss        | -17.6     |\n","|    reward             | 1.2533737 |\n","|    std                | 1.03      |\n","|    value_loss         | 2.47      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 145        |\n","|    iterations         | 8000       |\n","|    time_elapsed       | 274        |\n","|    total_timesteps    | 40000      |\n","| train/                |            |\n","|    entropy_loss       | -13.1      |\n","|    explained_variance | -1.19e-07  |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 7999       |\n","|    policy_loss        | 35         |\n","|    reward             | 0.29852238 |\n","|    std                | 1.03       |\n","|    value_loss         | 8.69       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 145       |\n","|    iterations         | 8100      |\n","|    time_elapsed       | 277       |\n","|    total_timesteps    | 40500     |\n","| train/                |           |\n","|    entropy_loss       | -13.1     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 8099      |\n","|    policy_loss        | 53.8      |\n","|    reward             | -2.905516 |\n","|    std                | 1.04      |\n","|    value_loss         | 21.6      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 145       |\n","|    iterations         | 8200      |\n","|    time_elapsed       | 282       |\n","|    total_timesteps    | 41000     |\n","| train/                |           |\n","|    entropy_loss       | -13.1     |\n","|    explained_variance | 1.19e-07  |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 8199      |\n","|    policy_loss        | -27.1     |\n","|    reward             | 7.6284714 |\n","|    std                | 1.04      |\n","|    value_loss         | 33.3      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 145       |\n","|    iterations         | 8300      |\n","|    time_elapsed       | 285       |\n","|    total_timesteps    | 41500     |\n","| train/                |           |\n","|    entropy_loss       | -13.2     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 8299      |\n","|    policy_loss        | 35.4      |\n","|    reward             | 3.7041981 |\n","|    std                | 1.05      |\n","|    value_loss         | 19.2      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 145       |\n","|    iterations         | 8400      |\n","|    time_elapsed       | 288       |\n","|    total_timesteps    | 42000     |\n","| train/                |           |\n","|    entropy_loss       | -13.2     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 8399      |\n","|    policy_loss        | -7.22     |\n","|    reward             | 0.7603612 |\n","|    std                | 1.05      |\n","|    value_loss         | 2.18      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 145        |\n","|    iterations         | 8500       |\n","|    time_elapsed       | 291        |\n","|    total_timesteps    | 42500      |\n","| train/                |            |\n","|    entropy_loss       | -13.2      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 8499       |\n","|    policy_loss        | 22.3       |\n","|    reward             | -0.5991697 |\n","|    std                | 1.05       |\n","|    value_loss         | 3.36       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 145       |\n","|    iterations         | 8600      |\n","|    time_elapsed       | 296       |\n","|    total_timesteps    | 43000     |\n","| train/                |           |\n","|    entropy_loss       | -13.3     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 8599      |\n","|    policy_loss        | -24.3     |\n","|    reward             | 2.1170962 |\n","|    std                | 1.06      |\n","|    value_loss         | 5.54      |\n","-------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 145         |\n","|    iterations         | 8700        |\n","|    time_elapsed       | 299         |\n","|    total_timesteps    | 43500       |\n","| train/                |             |\n","|    entropy_loss       | -13.2       |\n","|    explained_variance | 0           |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 8699        |\n","|    policy_loss        | 7.37        |\n","|    reward             | -0.49200967 |\n","|    std                | 1.06        |\n","|    value_loss         | 5.9         |\n","---------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 145        |\n","|    iterations         | 8800       |\n","|    time_elapsed       | 302        |\n","|    total_timesteps    | 44000      |\n","| train/                |            |\n","|    entropy_loss       | -13.2      |\n","|    explained_variance | 5.96e-08   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 8799       |\n","|    policy_loss        | 83.7       |\n","|    reward             | -2.0244424 |\n","|    std                | 1.06       |\n","|    value_loss         | 43.6       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 145       |\n","|    iterations         | 8900      |\n","|    time_elapsed       | 305       |\n","|    total_timesteps    | 44500     |\n","| train/                |           |\n","|    entropy_loss       | -13.3     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 8899      |\n","|    policy_loss        | 65.1      |\n","|    reward             | -2.655074 |\n","|    std                | 1.06      |\n","|    value_loss         | 26.6      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 145       |\n","|    iterations         | 9000      |\n","|    time_elapsed       | 309       |\n","|    total_timesteps    | 45000     |\n","| train/                |           |\n","|    entropy_loss       | -13.3     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 8999      |\n","|    policy_loss        | 4.3       |\n","|    reward             | 1.7328625 |\n","|    std                | 1.06      |\n","|    value_loss         | 2.47      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 145        |\n","|    iterations         | 9100       |\n","|    time_elapsed       | 313        |\n","|    total_timesteps    | 45500      |\n","| train/                |            |\n","|    entropy_loss       | -13.2      |\n","|    explained_variance | 1.19e-07   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 9099       |\n","|    policy_loss        | -9.49      |\n","|    reward             | 0.45227265 |\n","|    std                | 1.05       |\n","|    value_loss         | 0.538      |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 145        |\n","|    iterations         | 9200       |\n","|    time_elapsed       | 316        |\n","|    total_timesteps    | 46000      |\n","| train/                |            |\n","|    entropy_loss       | -13.3      |\n","|    explained_variance | -1.19e-07  |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 9199       |\n","|    policy_loss        | -24        |\n","|    reward             | 0.44854257 |\n","|    std                | 1.06       |\n","|    value_loss         | 5.48       |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 145         |\n","|    iterations         | 9300        |\n","|    time_elapsed       | 319         |\n","|    total_timesteps    | 46500       |\n","| train/                |             |\n","|    entropy_loss       | -13.3       |\n","|    explained_variance | 0           |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 9299        |\n","|    policy_loss        | 16.5        |\n","|    reward             | -0.67021066 |\n","|    std                | 1.06        |\n","|    value_loss         | 5.85        |\n","---------------------------------------\n","----------------------------------------\n","| time/                 |              |\n","|    fps                | 145          |\n","|    iterations         | 9400         |\n","|    time_elapsed       | 322          |\n","|    total_timesteps    | 47000        |\n","| train/                |              |\n","|    entropy_loss       | -13.3        |\n","|    explained_variance | 0            |\n","|    learning_rate      | 0.0007       |\n","|    n_updates          | 9399         |\n","|    policy_loss        | -34.2        |\n","|    reward             | -0.009986861 |\n","|    std                | 1.07         |\n","|    value_loss         | 6.28         |\n","----------------------------------------\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 145      |\n","|    iterations         | 9500     |\n","|    time_elapsed       | 327      |\n","|    total_timesteps    | 47500    |\n","| train/                |          |\n","|    entropy_loss       | -13.3    |\n","|    explained_variance | 0        |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 9499     |\n","|    policy_loss        | 9.61     |\n","|    reward             | -1.69888 |\n","|    std                | 1.06     |\n","|    value_loss         | 3.09     |\n","------------------------------------\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 145      |\n","|    iterations         | 9600     |\n","|    time_elapsed       | 330      |\n","|    total_timesteps    | 48000    |\n","| train/                |          |\n","|    entropy_loss       | -13.3    |\n","|    explained_variance | 0        |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 9599     |\n","|    policy_loss        | 104      |\n","|    reward             | 6.863434 |\n","|    std                | 1.07     |\n","|    value_loss         | 89.2     |\n","------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 145        |\n","|    iterations         | 9700       |\n","|    time_elapsed       | 333        |\n","|    total_timesteps    | 48500      |\n","| train/                |            |\n","|    entropy_loss       | -13.3      |\n","|    explained_variance | -1.19e-07  |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 9699       |\n","|    policy_loss        | -20.8      |\n","|    reward             | -0.3568112 |\n","|    std                | 1.07       |\n","|    value_loss         | 7.21       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 145       |\n","|    iterations         | 9800      |\n","|    time_elapsed       | 336       |\n","|    total_timesteps    | 49000     |\n","| train/                |           |\n","|    entropy_loss       | -13.3     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 9799      |\n","|    policy_loss        | -57.5     |\n","|    reward             | 1.3855414 |\n","|    std                | 1.07      |\n","|    value_loss         | 18.2      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 145        |\n","|    iterations         | 9900       |\n","|    time_elapsed       | 340        |\n","|    total_timesteps    | 49500      |\n","| train/                |            |\n","|    entropy_loss       | -13.3      |\n","|    explained_variance | -1.19e-07  |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 9899       |\n","|    policy_loss        | 31.6       |\n","|    reward             | 0.74794465 |\n","|    std                | 1.06       |\n","|    value_loss         | 6.03       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 145       |\n","|    iterations         | 10000     |\n","|    time_elapsed       | 344       |\n","|    total_timesteps    | 50000     |\n","| train/                |           |\n","|    entropy_loss       | -13.3     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 9999      |\n","|    policy_loss        | 32.4      |\n","|    reward             | 1.7319541 |\n","|    std                | 1.06      |\n","|    value_loss         | 7.48      |\n","-------------------------------------\n","hit end!\n","==============Get Baseline Stats===========\n","[*********************100%***********************]  1 of 1 completed\n","Shape of DataFrame:  (439, 8)\n","Annual return          0.001356\n","Cumulative returns     0.002364\n","Annual volatility      0.172017\n","Sharpe ratio           0.093792\n","Calmar ratio           0.006181\n","Stability              0.144923\n","Max drawdown          -0.219408\n","Omega ratio            1.015835\n","Sortino ratio          0.132159\n","Skew                        NaN\n","Kurtosis                    NaN\n","Tail ratio             1.028372\n","Daily value at risk   -0.021608\n","dtype: float64\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/pyfolio/timeseries.py:724: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n","  stats = pd.Series()\n"]},{"name":"stdout","output_type":"stream","text":["a2c 로 얻은 투자 수익률 >> 3.06 %\n","3.06 %\n"]},{"data":{"text/html":["\n","  <div id=\"df-1b149b39-d999-4f33-a7af-0e0cd630ee2c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>XLB</th>\n","      <th>XLE</th>\n","      <th>XLF</th>\n","      <th>XLI</th>\n","      <th>XLK</th>\n","      <th>XLP</th>\n","      <th>XLU</th>\n","      <th>XLV</th>\n","      <th>XLY</th>\n","    </tr>\n","    <tr>\n","      <th>date</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2021-10-01</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>9464</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1586</td>\n","      <td>0</td>\n","      <td>1073</td>\n","    </tr>\n","    <tr>\n","      <th>2021-10-04</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>9943</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-10-05</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-10000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7084</td>\n","      <td>-1586</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-10-06</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-9407</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1966</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b149b39-d999-4f33-a7af-0e0cd630ee2c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1b149b39-d999-4f33-a7af-0e0cd630ee2c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1b149b39-d999-4f33-a7af-0e0cd630ee2c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["            XLB  XLE    XLF  XLI  XLK   XLP   XLU  XLV   XLY\n","date                                                        \n","2021-10-01    0    0   9464    0    0     0  1586    0  1073\n","2021-10-04    0    0   9943    0    0     0     0    0     0\n","2021-10-05    0    0 -10000    0    0  7084 -1586    0     0\n","2021-10-06    0    0  -9407    0    0     2     0    0  1966"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["if __name__==\"__main__\":\n","  ############# parameter ####################\n","\n","  # TRADE_END_DATE = '2023-07-01' # 이거 사용안함(module안에 녹임)\n","\n","  strategy = ['a2c','ddpg','ppo','td3','sac']\n","  using = strategy[0]\n","\n","  tickers = ['XLB','XLE','XLF','XLI','XLK','XLP','XLU','XLV','XLY'] # 포트폴리오 구성종목\n","  # default로 하면 model load하고, tickers 고치면 다시 training한다.\n","\n","\n","  epochs = 200 # trade-off 이거 크면 dlinear training 시간 많이 걸림\n","\n","\n","  earning_rate, cash, record = finrl_module.finrl_main(tickers, using, epochs, FORCAST_SIZE=30, tolerance=0.0001, hmax=10000, initial_amount=1000000)\n","\n","print(earning_rate,'%')\n","record.loc[~(record == 0).all(axis=1)]"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":455},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1688207526730,"user":{"displayName":"박민규","userId":"12628046480347201618"},"user_tz":-540},"id":"8wcT9Gh8knpm","outputId":"597082dd-90e1-4779-89ca-c98825bdf8f8"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-6398144d-6032-4ecc-a923-5b6af75d9752\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>XLB</th>\n","      <th>XLE</th>\n","      <th>XLF</th>\n","      <th>XLI</th>\n","      <th>XLK</th>\n","      <th>XLP</th>\n","      <th>XLU</th>\n","      <th>XLV</th>\n","      <th>XLY</th>\n","    </tr>\n","    <tr>\n","      <th>date</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2021-10-01</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>9464</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1586</td>\n","      <td>0</td>\n","      <td>1073</td>\n","    </tr>\n","    <tr>\n","      <th>2021-10-04</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>9943</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-10-05</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-10000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7084</td>\n","      <td>-1586</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-10-06</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-9407</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1966</td>\n","    </tr>\n","    <tr>\n","      <th>2021-10-07</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2023-06-22</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2023-06-23</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2023-06-26</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2023-06-27</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2023-06-28</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>437 rows × 9 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6398144d-6032-4ecc-a923-5b6af75d9752')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6398144d-6032-4ecc-a923-5b6af75d9752 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6398144d-6032-4ecc-a923-5b6af75d9752');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["            XLB  XLE    XLF  XLI  XLK   XLP   XLU  XLV   XLY\n","date                                                        \n","2021-10-01    0    0   9464    0    0     0  1586    0  1073\n","2021-10-04    0    0   9943    0    0     0     0    0     0\n","2021-10-05    0    0 -10000    0    0  7084 -1586    0     0\n","2021-10-06    0    0  -9407    0    0     2     0    0  1966\n","2021-10-07    0    0      0    0    0     0     0    0     0\n","...         ...  ...    ...  ...  ...   ...   ...  ...   ...\n","2023-06-22    0    0      0    0    0     0     0    0     0\n","2023-06-23    0    0      0    0    0     0     0    0     0\n","2023-06-26    0    0      0    0    0     0     0    0     0\n","2023-06-27    0    0      0    0    0     0     0    0     0\n","2023-06-28    0    0      0    0    0     0     0    0     0\n","\n","[437 rows x 9 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["record"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iZST5R5ZAoSp"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPwfSRCUOd77ILrCJPV3YLG","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
